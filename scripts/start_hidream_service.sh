#!/bin/bash

set -e

# ğŸ¨ HiDream-I1 API æœåŠ¡å¯åŠ¨è„šæœ¬

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m'

# é»˜è®¤é…ç½®
DEVICE_TYPE="npu"
DEVICE_COUNT=""
PORT=8088
HOST="0.0.0.0"
HIDREAM_MODEL_PATH="/data/HiDream-I1-Full"
HIDREAM_EXTRA_MODEL_PATH="/data/Llama-3.1-8B-Instruct"
HIDREAM_PROJECT_PATH=""

# æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
show_help() {
    echo "ğŸ¨ HiDream-I1 API Service Startup Script"
    echo ""
    echo "Usage: $0 [OPTIONS]"
    echo ""
    echo "Options:"
    echo "  -m, --model-path PATH          HiDream-I1-Fullæ¨¡å‹è·¯å¾„ (é»˜è®¤: /data/HiDream-I1-Full)"
    echo "  -e, --extra-model-path PATH    Llama-3.1-8B-Instructæ¨¡å‹è·¯å¾„ (é»˜è®¤: /data/Llama-3.1-8B-Instruct)"
    echo "  -p, --project-path PATH        HiDream-I1é¡¹ç›®è·¯å¾„ (è‡ªåŠ¨æ£€æµ‹æˆ–æ‰‹åŠ¨æŒ‡å®š)"
    echo "  -d, --devices DEVICES          NPUè®¾å¤‡åˆ—è¡¨ï¼Œé€—å·åˆ†éš” (å¦‚: 4,5,6,7)"
    echo "  -c, --device-count COUNT       è®¾å¤‡æ•°é‡ (è‡ªåŠ¨ä»devicesè®¡ç®—)"
    echo "  -t, --device-type TYPE         è®¾å¤‡ç±»å‹: npu, cuda (é»˜è®¤: npu)"
    echo "  --port PORT                    æœåŠ¡ç«¯å£ (é»˜è®¤: 8088)"
    echo "  --host HOST                    æœåŠ¡åœ°å€ (é»˜è®¤: 0.0.0.0)"
    echo "  -h, --help                     æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯"
    echo ""
    echo "Examples:"
    echo "  # ä½¿ç”¨é»˜è®¤é…ç½®å¯åŠ¨"
    echo "  $0"
    echo ""
    echo "  # æŒ‡å®šNPUè®¾å¤‡å¯åŠ¨"
    echo "  $0 -d 4,5,6,7"
    echo ""
    echo "  # å®Œæ•´é…ç½®å¯åŠ¨"
    echo "  $0 -m /data/HiDream-I1-Full -e /data/Llama-3.1-8B-Instruct -p /workspace/HiDream-I1 -d 4,5,6,7"
    echo ""
    echo "  # å•å¡æ¨¡å¼"
    echo "  $0 -d 4 -c 1"
}

# è§£æå‘½ä»¤è¡Œå‚æ•°
while [[ $# -gt 0 ]]; do
    case $1 in
        -m|--model-path)
            HIDREAM_MODEL_PATH="$2"
            shift 2
            ;;
        -e|--extra-model-path)
            HIDREAM_EXTRA_MODEL_PATH="$2"
            shift 2
            ;;
        -p|--project-path)
            HIDREAM_PROJECT_PATH="$2"
            shift 2
            ;;
        -d|--devices)
            export ASCEND_RT_VISIBLE_DEVICES="$2"
            shift 2
            ;;
        -c|--device-count)
            DEVICE_COUNT="$2"
            shift 2
            ;;
        -t|--device-type)
            DEVICE_TYPE="$2"
            shift 2
            ;;
        --port)
            PORT="$2"
            shift 2
            ;;
        --host)
            HOST="$2"
            shift 2
            ;;
        -h|--help)
            show_help
            exit 0
            ;;
        *)
            echo "Unknown option: $1"
            show_help
            exit 1
            ;;
    esac
done

echo -e "${BLUE}ğŸ¨ HiDream-I1 API Service Startup${NC}"

# ğŸ”¥ æ™ºèƒ½è®¾å¤‡è®¡æ•°
if [ -n "$ASCEND_RT_VISIBLE_DEVICES" ]; then
    IFS=',' read -ra DEVICE_ARRAY <<< "$ASCEND_RT_VISIBLE_DEVICES"
    DETECTED_DEVICE_COUNT=${#DEVICE_ARRAY[@]}
    DEVICE_COUNT=${DEVICE_COUNT:-$DETECTED_DEVICE_COUNT}
else
    DEVICE_COUNT=${DEVICE_COUNT:-1}
    export ASCEND_RT_VISIBLE_DEVICES=$(seq -s, 0 $((DEVICE_COUNT-1)))
fi

# ğŸ”¥ æ™ºèƒ½é¡¹ç›®è·¯å¾„æ£€æµ‹
if [ -z "$HIDREAM_PROJECT_PATH" ]; then
    echo "ğŸ” Auto-detecting HiDream-I1 project path..."
    POSSIBLE_PATHS=(
        "/workspace/HiDream-I1"
        "/data/HiDream-I1" 
        "$HOME/HiDream-I1"
        "$(pwd)/HiDream-I1"
        "$(dirname $(pwd))/HiDream-I1"
        "$(pwd)"
    )
    
    for path in "${POSSIBLE_PATHS[@]}"; do
        if [ -f "$path/inference.py" ]; then
            HIDREAM_PROJECT_PATH="$path"
            echo "  âœ… Found: $path"
            break
        fi
    done
    
    if [ -z "$HIDREAM_PROJECT_PATH" ]; then
        echo -e "${RED}âŒ HiDream-I1 project not found in common paths${NC}"
        echo "Please specify with: -p /path/to/HiDream-I1"
        exit 1
    fi
fi

echo -e "${BLUE}ğŸ“‹ Configuration:${NC}"
echo "  - Device: $DEVICE_TYPE ($DEVICE_COUNT devices)"
echo "  - NPU Devices: $ASCEND_RT_VISIBLE_DEVICES"
echo "  - Server: $HOST:$PORT"
echo "  - Model: $HIDREAM_MODEL_PATH"
echo "  - Extra Model: $HIDREAM_EXTRA_MODEL_PATH"
echo "  - Project Path: $HIDREAM_PROJECT_PATH"

# éªŒè¯è·¯å¾„
echo "ğŸ” Validating paths..."
if [ ! -d "$HIDREAM_MODEL_PATH" ]; then
    echo -e "${RED}âŒ Model path not found: $HIDREAM_MODEL_PATH${NC}"
    exit 1
fi

if [ ! -d "$HIDREAM_EXTRA_MODEL_PATH" ]; then
    echo -e "${RED}âŒ Extra model path not found: $HIDREAM_EXTRA_MODEL_PATH${NC}"
    exit 1
fi

if [ ! -d "$HIDREAM_PROJECT_PATH" ]; then
    echo -e "${RED}âŒ HiDream-I1 project path not found: $HIDREAM_PROJECT_PATH${NC}"
    exit 1
fi

if [ ! -f "$HIDREAM_PROJECT_PATH/inference.py" ]; then
    echo -e "${RED}âŒ inference.py not found in: $HIDREAM_PROJECT_PATH${NC}"
    exit 1
fi

echo "  âœ… All paths validated"

# åˆ›å»ºå¿…è¦ç›®å½•
mkdir -p logs
mkdir -p generated_images

# ç¯å¢ƒå˜é‡è®¾ç½®
export HIDREAM_MODEL_PATH="$HIDREAM_MODEL_PATH"
export HIDREAM_EXTRA_MODEL_PATH="$HIDREAM_EXTRA_MODEL_PATH"
export HIDREAM_PROJECT_PATH="$HIDREAM_PROJECT_PATH"
export DEVICE_TYPE="$DEVICE_TYPE"
export DEVICE_COUNT="$DEVICE_COUNT"

# ğŸ”¥ NPUç¯å¢ƒè®¾ç½®
if [ "$DEVICE_TYPE" = "npu" ]; then
    echo -e "${BLUE}ğŸ“± NPU Environment Setup...${NC}"
    
    # æ£€æŸ¥torchrunå¯ç”¨æ€§
    if [ "$DEVICE_COUNT" -gt 1 ]; then
        echo "ğŸ”§ Checking torchrun for distributed inference..."
        if command -v torchrun >/dev/null 2>&1; then
            echo "  âœ… torchrun found: $(which torchrun)"
        else
            echo "  âŒ torchrun not found, required for multi-NPU"
            echo "  ğŸ’¡ Install with: pip install torch"
            exit 1
        fi
    fi
    
    # NPUä¼˜åŒ–é…ç½®
    export ACL_STREAM_TIMEOUT="7200"
    export PYTORCH_NPU_ALLOC_CONF="max_split_size_mb:512"
    export TOKENIZERS_PARALLELISM="false"
    
    if [ "$DEVICE_COUNT" -gt 1 ]; then
        # å¤šå¡é…ç½®
        export HCCL_TIMEOUT="7200"
        export HCCL_BUFFSIZE="2048"
        export HCCL_SINGLE_NODE="1"
        export HCCL_LOCAL_RANK_NUM="$DEVICE_COUNT"
        export HCCL_WHITELIST_DISABLE="1"
        export HCCL_SECURITY_ENABLE="0"
        echo "  - Multi-NPU mode: $DEVICE_COUNT devices"
        echo "  - Torchrun ready for distributed inference"
    else
        # å•å¡é…ç½®
        export HCCL_DISABLE="1"
        echo "  - Single-NPU mode"
    fi
    
    echo "  - NPU Devices: $ASCEND_RT_VISIBLE_DEVICES"
    echo "  - Memory Config: max_split_size_mb=512"
fi

# æ¸…ç†æ—§è¿›ç¨‹
echo -e "${YELLOW}ğŸ§¹ Cleaning up old processes...${NC}"
pkill -f "hidream_api.py" 2>/dev/null || true
pkill -f "uvicorn.*hidream" 2>/dev/null || true
sleep 2

# å¯åŠ¨æœåŠ¡
echo -e "${GREEN}ğŸš€ Starting HiDream-I1 API Service...${NC}"

LOG_FILE="logs/hidream_api_$(date +%Y%m%d_%H%M%S).log"

# åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•å¹¶å¯åŠ¨
cd "$(dirname "$0")/../src"

python3 -m uvicorn hidream_api:app \
    --host "$HOST" \
    --port "$PORT" \
    --workers 1 \
    --log-level info \
    --access-log \
    2>&1 | tee "../$LOG_FILE" &

SERVER_PID=$!

# ç­‰å¾…æœåŠ¡å¯åŠ¨
echo -e "${BLUE}â³ Waiting for service to start...${NC}"
sleep 5

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
if kill -0 $SERVER_PID 2>/dev/null; then
    echo -e "${GREEN}âœ… HiDream-I1 API Service started successfully!${NC}"
    echo -e "${BLUE}ğŸ”— Service URL: http://$HOST:$PORT${NC}"
    echo -e "${BLUE}ğŸ“– API Docs: http://$HOST:$PORT/docs${NC}"
    echo -e "${BLUE}ğŸ” Health Check: http://$HOST:$PORT/health${NC}"
    echo -e "${BLUE}ğŸ“Š Logs: tail -f $LOG_FILE${NC}"
    
    echo -e "${BLUE}ğŸ“‹ Final Configuration:${NC}"
    echo "  - NPU Devices: $ASCEND_RT_VISIBLE_DEVICES"
    echo "  - Device Count: $DEVICE_COUNT"
    echo "  - Process ID: $SERVER_PID"
    echo "  - Project Path: $HIDREAM_PROJECT_PATH"
    
    # ç­‰å¾…ç”¨æˆ·ä¸­æ–­
    trap "echo -e '${YELLOW}ğŸ›‘ Shutting down...${NC}'; kill $SERVER_PID; exit 0" INT
    wait $SERVER_PID
else
    echo -e "${RED}âŒ Failed to start HiDream-I1 API Service${NC}"
    echo -e "${RED}ğŸ’¡ Check the log file: $LOG_FILE${NC}"
    exit 1
fi