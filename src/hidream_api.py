import os
import uuid
import asyncio
import threading
from datetime import datetime
from collections import deque
from typing import Dict, List, Optional
from pathlib import Path

from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
import uvicorn

from models import *
from pipelines.hidream_pipeline_factory import create_pipeline
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_app():
    app = FastAPI(title="HiDream-I1 Image Generation API", version="1.0.0")
    
    # ğŸ”¥ å…¨å±€çŠ¶æ€ç®¡ç†
    status_dict: Dict[str, dict] = {}
    task_queue = deque()
    
    # ğŸ”¥ åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs("generated_images", exist_ok=True)
    app.mount("/images", StaticFiles(directory="generated_images"), name="images")
    
    # ğŸ”¥ åˆå§‹åŒ–æ¨¡å‹ç®¡é“
    pipeline = None
    
    def init_pipeline():
        nonlocal pipeline
        try:
            model_path = os.getenv("HIDREAM_MODEL_PATH", "/data/HiDream-I1-Full")
            extra_model_path = os.getenv("HIDREAM_EXTRA_MODEL_PATH", "/data/Llama-3.1-8B-Instruct")
            device_type = os.getenv("DEVICE_TYPE", "npu")
            device_count = int(os.getenv("DEVICE_COUNT", "1"))
            
            logger.info(f"ğŸ”§ Initializing pipeline with:")
            logger.info(f"  - Model path: {model_path}")
            logger.info(f"  - Extra model path: {extra_model_path}")
            logger.info(f"  - Device: {device_type} ({device_count} devices)")
            
            pipeline = create_pipeline(
                model_path=model_path,
                extra_model_path=extra_model_path,
                device_type=device_type,
                device_count=device_count
            )
            logger.info("ğŸš€ HiDream-I1 pipeline initialized successfully")
        except Exception as e:
            logger.error(f"âŒ Failed to initialize pipeline: {e}")
            raise e
    
    def process_task(task_id: str, request: ImageGenerationRequest):
        """å¤„ç†å•ä¸ªå›¾åƒç”Ÿæˆä»»åŠ¡"""
        try:
            logger.info(f"ğŸ¨ Starting image generation for task {task_id}")
            logger.info(f"ğŸ“ Prompt: {request.prompt[:100]}...")

            # æ›´æ–°çŠ¶æ€
            status_dict[task_id]["status"] = TaskStatus.PROCESSING
            status_dict[task_id]["progress"] = 10

            # è°ƒç”¨æ¨¡å‹ç”Ÿæˆ
            start_time = datetime.now()

            result_paths = pipeline.generate_images(
                task_id=task_id,
                request=request,
                progress_callback=lambda p: update_progress(task_id, p)
            )

            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()

            # ç”Ÿæˆè®¿é—®URL
            base_url = os.getenv("API_BASE_URL", "http://localhost:8088")
            result_urls = [f"{base_url}/images/{os.path.basename(path)}" 
                          for path in result_paths]

            # æ›´æ–°å®ŒæˆçŠ¶æ€
            status_dict[task_id].update({
                "status": TaskStatus.COMPLETED,
                "progress": 100,
                "result_urls": result_urls,
                "completed_at": end_time.isoformat(),
                "processing_time": processing_time
            })

            logger.info(f"âœ… Task {task_id} completed in {processing_time:.2f}s")
            logger.info(f"ğŸ“¸ Generated {len(result_paths)} images")

        except KeyboardInterrupt:
            logger.info(f"ğŸ›‘ Task {task_id} interrupted by user")
            status_dict[task_id].update({
                "status": TaskStatus.FAILED,
                "error": "Task interrupted",
                "completed_at": datetime.now().isoformat()
            })
            raise
        except Exception as e:
            logger.error(f"âŒ Task {task_id} failed: {str(e)}")
            status_dict[task_id].update({
                "status": TaskStatus.FAILED,
                "error": str(e),
                "completed_at": datetime.now().isoformat()
            })

    def update_progress(task_id: str, progress: int):
        """æ›´æ–°ä»»åŠ¡è¿›åº¦"""
        if task_id in status_dict:
            status_dict[task_id]["progress"] = min(progress, 95)  # ç”Ÿæˆå®Œæˆå‰ä¿æŒ95%
            logger.debug(f"ğŸ“Š Task {task_id} progress: {progress}%")
    
    def task_worker():
        """åå°ä»»åŠ¡å¤„ç†å™¨"""
        logger.info("ğŸ”„ Task worker started")
        while True:
            try:
                if task_queue and pipeline is not None:
                    task_id, request = task_queue.popleft()
                    logger.info(f"ğŸ¯ Processing task {task_id} from queue")
                    process_task(task_id, request)
                else:
                    threading.Event().wait(1)  # ç­‰å¾…1ç§’
            except Exception as e:
                logger.error(f"âŒ Task worker error: {e}")
                threading.Event().wait(5)  # é”™è¯¯åç­‰å¾…5ç§’
    
    # ğŸ”¥ å¯åŠ¨åå°ä»»åŠ¡å¤„ç†å™¨
    threading.Thread(target=task_worker, daemon=True).start()
    
    @app.on_event("startup")
    async def startup_event():
        """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–"""
        logger.info("ğŸš€ Starting HiDream-I1 API Server...")
        try:
            init_pipeline()
            logger.info("âœ… HiDream-I1 API Server ready!")
        except Exception as e:
            logger.error(f"âŒ Failed to start API server: {e}")
            raise e
    
    @app.get("/")
    async def root():
        return {
            "message": "HiDream-I1 Image Generation API", 
            "status": "running",
            "version": "1.0.0"
        }
    
    @app.get("/health")
    async def health():
        return {
            "status": "healthy",
            "pipeline_ready": pipeline is not None,
            "queue_length": len(task_queue),
            "active_tasks": len([t for t in status_dict.values() 
                               if t["status"] == TaskStatus.PROCESSING]),
            "total_tasks": len(status_dict)
        }
    
    @app.post("/submit", response_model=ImageSubmitResponse)
    async def submit(request: ImageGenerationRequest):
        """æäº¤å›¾åƒç”Ÿæˆä»»åŠ¡"""
        if pipeline is None:
            raise HTTPException(status_code=503, detail="Pipeline not ready")
        
        task_id = f"img_{uuid.uuid4().hex[:16]}"
        
        # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
        status_dict[task_id] = {
            "status": TaskStatus.PENDING,
            "progress": 0,
            "result_urls": [],
            "error": "",
            "created_at": datetime.now().isoformat(),
            "request": request.model_dump() if hasattr(request, 'model_dump') else request.dict()
        }
        
        # æ·»åŠ åˆ°é˜Ÿåˆ—
        task_queue.append((task_id, request))
        
        logger.info(f"ğŸ“ Task submitted: {task_id}")
        logger.info(f"ğŸ“‹ Queue length: {len(task_queue)}")
        
        # ä¼°ç®—å¤„ç†æ—¶é—´
        estimated_time = estimate_processing_time(request)
        
        return ImageSubmitResponse(
            requestId=task_id,
            status=TaskStatus.PENDING,
            message="ä»»åŠ¡å·²æäº¤ï¼Œæ­£åœ¨é˜Ÿåˆ—ä¸­ç­‰å¾…å¤„ç†",
            estimated_time=estimated_time
        )
    
    @app.post("/batch_submit", response_model=List[ImageSubmitResponse])
    async def batch_submit(batch_request: BatchImageRequest):
        """æ‰¹é‡æäº¤å›¾åƒç”Ÿæˆä»»åŠ¡"""
        if pipeline is None:
            raise HTTPException(status_code=503, detail="Pipeline not ready")
        
        responses = []
        for req in batch_request.requests:
            task_id = f"img_{uuid.uuid4().hex[:16]}"
            
            status_dict[task_id] = {
                "status": TaskStatus.PENDING,
                "progress": 0,
                "result_urls": [],
                "error": "",
                "created_at": datetime.now().isoformat(),
                "request": req.model_dump() if hasattr(req, 'model_dump') else req.dict()
            }
            
            task_queue.append((task_id, req))
            estimated_time = estimate_processing_time(req)
            
            responses.append(ImageSubmitResponse(
                requestId=task_id,
                status=TaskStatus.PENDING,
                message="æ‰¹é‡ä»»åŠ¡å·²æäº¤",
                estimated_time=estimated_time
            ))
        
        logger.info(f"ğŸ“¦ Batch submitted: {len(responses)} tasks")
        return responses
        
    @app.get("/status/{task_id}", response_model=ImageStatusResponse)
    async def get_status(task_id: str):
        """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
        if task_id not in status_dict:
            raise HTTPException(status_code=404, detail="Task not found")
        
        task_info = status_dict[task_id]
        return ImageStatusResponse(**task_info)
    
    @app.get("/download/{task_id}")
    async def download_result(task_id: str, image_index: int = 0):
        """ä¸‹è½½ç”Ÿæˆçš„å›¾ç‰‡"""
        if task_id not in status_dict:
            raise HTTPException(status_code=404, detail="Task not found")
        
        task_info = status_dict[task_id]
        if task_info["status"] != TaskStatus.COMPLETED:
            raise HTTPException(status_code=400, detail="Task not completed")
        
        if not task_info["result_urls"] or image_index >= len(task_info["result_urls"]):
            raise HTTPException(status_code=404, detail="Image not found")
        
        # ä»URLæå–æ–‡ä»¶è·¯å¾„
        image_url = task_info["result_urls"][image_index]
        filename = image_url.split("/")[-1]
        file_path = f"generated_images/{filename}"
        
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="Image file not found")
        
        return FileResponse(
            file_path,
            media_type="image/png",
            filename=f"{task_id}_image_{image_index}.png"
        )
    
    def estimate_processing_time(request: ImageGenerationRequest) -> int:
        """ä¼°ç®—å¤„ç†æ—¶é—´"""
        base_time = 15  # åŸºç¡€æ—¶é—´15ç§’
        
        # æ ¹æ®å‚æ•°è°ƒæ•´
        step_factor = request.num_inference_steps / 50  # æ­¥æ•°å› å­
        image_factor = request.num_images_per_prompt      # å›¾ç‰‡æ•°é‡å› å­
        resolution_factor = 1.0
        
        if "2048" in request.resolution:
            resolution_factor = 2.0
        elif "1536" in request.resolution:
            resolution_factor = 1.5
        
        estimated = int(base_time * step_factor * image_factor * resolution_factor)
        return max(estimated, 5)  # æœ€å°‘5ç§’
    
    return app

# ğŸ”¥ ç›´æ¥è¿è¡Œæ¨¡å¼
app = create_app()

if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8088,
        log_level="info"
    )